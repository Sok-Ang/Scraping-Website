import requests
from bs4 import BeautifulSoup
import pandas as pd

books = []

#Pages Website from 1 to n.
for i in range(1, n):
    url = f"https://books.toscrape.com/catalogue/page-{i}.html"
    response = requests.get(url)
    response = response.content
    soup = BeautifulSoup(response, 'html.parser')
    ol = soup.find('ol')
    article = ol.find_all('article', class_='product_pod')
    for articles in article:
        image = articles.find('img')
        title = image.attrs['alt']
        startag = articles.find('p')
        star = startag['class'][1]
        price = articles.find('p', class_='price_color').text
        price = float(price[1:])
        books.append([title, star, price])

#Download Data into file.csv
df = pd.DataFrame(books, columns=['Title', 'Star Rating', 'Price'])
df.to_csv('books.csv')

